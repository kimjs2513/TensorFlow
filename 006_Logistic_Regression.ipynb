{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "006 Logistic Regression",
      "provenance": [],
      "authorship_tag": "ABX9TyOQIw8LHIdwGE8nGHRKLpoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimjs2513/TensorFlow/blob/master/006_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSmTjuTM0kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic Regression  텐서플로우로 구현하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Hk4WMT4p_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "f415376f-f74d-4fe2-da79-eb2ac4b515eb"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "x_train = [[1., 2.], [2., 3.], [3., 1.], [4., 3.], [5., 3.], [6., 2.]]\n",
        "y_train = [[0.], [0.], [0.], [1.], [1.], [1.]]\n",
        "\n",
        "x_test = [[5., 2.]]\n",
        "y_test = [[1.]]\n",
        "\n",
        "x1 = [x[0] for x in x_train]\n",
        "x2 = [x[1] for x in x_train]\n",
        "\n",
        "colors = [int(y[0] % 3) for y in y_train]\n",
        "plt.scatter(x1, x2, c = colors, marker='^')\n",
        "plt.scatter(x_test[0][0], x_test[0][1], c='red')\n",
        "\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()\n",
        "\n",
        "#0의 값을 가지는 것들은 보라색, 1의 값은 노란색으로 나타나며, 테스트 값은 빨간색으로 나타난다.\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) #x_train데이터를 1행 2열의 행렬과, y_train데이터를 1행1열의 행렬로 만들어준다  # [0, 0] [0] * 6\n",
        "\n",
        "W = tf.Variable(tf.zeros([2, 1]), name = 'weight')  \n",
        "b = tf.Variable(tf.zeros([1]), name = 'bias')\n",
        "#연산을 위해 W를 2행 1열의 행렬로 만들어주고, b를 1행 1열로 만들어 준다.\n",
        "'''\n",
        "X[0 0]W[0] + b[0] = y[0]\n",
        "       [0]\n",
        "'''\n",
        "\n",
        "def logistic_regression(features): #sigmoid 함수 만들어주기\n",
        "    hypothesis = tf.divide(1., 1. + tf.exp(-tf.matmul(features, W) + b)) #mat.mul은 행렬곱을 의미\n",
        "    # 1 / 1 + e^x\n",
        "    # x = H(X) = XW + b\n",
        "    return hypothesis\n",
        "\n",
        "def loss_fn(hypothesis, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
        "    # cost(h(x), y) = -ylog(h(x)) - (1 - y)log(1 - h(x))\n",
        "    return cost\n",
        "\n",
        "# Gradient Descent\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01) #cost값을 줄이는 것을 선언, Gradient descent\n",
        "\n",
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32) #0.5이상이명 1, 0.5이하면 0 return\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype = tf.int32)) #predicted값과 labels값이 일치하면 accuracy 증가\n",
        "    # equl: predicted, label 일치하는지 비교\n",
        "    # cast : True -> 1, False -> 0 return\n",
        "    # reduce_mean -> 해당 값들 평균\n",
        "    return accuracy\n",
        "\n",
        "def grad(features, labels):\n",
        "    with tf.GradientTape() as tape: #gradienttape()를 이용해 미분값을 기록\n",
        "        hypothesis = logistic_regression(features)\n",
        "        loss_value = loss_fn(hypothesis, labels)\n",
        "    return tape.gradient(loss_value, [W, b])\n",
        "\n",
        "EPOCHS = 1001 #학습 횟수, iteration: 데이터를 몇번에 나누어서 주는지, batch size: iteration마다 주는 데이터 사이즈\n",
        "\n",
        "for step in range(EPOCHS):\n",
        "    for features, labels in iter(dataset.batch(len(x_train))):  # x_train 의 길이만큼 dataset 가져오기\n",
        "        hypothesis = logistic_regression(features) #가설 함수 값\n",
        "        grads = grad(features, labels) # 미분 값\n",
        "        optimizer.apply_gradients(grads_and_vars = zip(grads, [W, b])) # W, b 값 업데이트\n",
        "        \n",
        "        if step % 100 == 0:\n",
        "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(hypothesis, labels)))\n",
        "            \n",
        "test_acc = accuracy_fn(logistic_regression(x_test), y_test)\n",
        "print(\"Test Result = {}\".format(tf.cast(logistic_regression(x_test) > 0.5, dtype = tf.int32)))\n",
        "print(\"Testset Accuracy : {:.4f}\".format(test_acc))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iter: 0, Loss: 0.6931\n",
            "Iter: 100, Loss: 0.5781\n",
            "Iter: 200, Loss: 0.5352\n",
            "Iter: 300, Loss: 0.5056\n",
            "Iter: 400, Loss: 0.4840\n",
            "Iter: 500, Loss: 0.4673\n",
            "Iter: 600, Loss: 0.4537\n",
            "Iter: 700, Loss: 0.4421\n",
            "Iter: 800, Loss: 0.4320\n",
            "Iter: 900, Loss: 0.4229\n",
            "Iter: 1000, Loss: 0.4145\n",
            "Test Result = [[1]]\n",
            "Testset Accuracy : 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_zzgU6e6ZLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}